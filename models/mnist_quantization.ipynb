{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-model-optimization"
      ],
      "metadata": {
        "id": "tW_c250QErxC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zwDu9CS6Eeh4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, AveragePooling2D, Flatten, Softmax, Dense, ReLU, BatchNormalization\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "quantize_model = tfmot.quantization.keras.quantize_model"
      ],
      "metadata": {
        "id": "Or13lcHmEg7t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "S150IfZ6Enw-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert y_train into one-hot format\n",
        "temp = []\n",
        "for i in range(len(y_train)):\n",
        "    temp.append(to_categorical(y_train[i], num_classes=10))\n",
        "y_train = np.array(temp)\n",
        "# Convert y_test into one-hot format\n",
        "temp = []\n",
        "for i in range(len(y_test)):    \n",
        "    temp.append(to_categorical(y_test[i], num_classes=10))\n",
        "y_test = np.array(temp)"
      ],
      "metadata": {
        "id": "-2leSVDxExXc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reshaping\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
      ],
      "metadata": {
        "id": "9jXXRXAAEySd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(28,28,1))\n",
        "# out = Lambda(lambda x: x/100)(inputs)\n",
        "out = Conv2D(4, 3, use_bias=False)(inputs)\n",
        "out = BatchNormalization()(out)\n",
        "out = ReLU()(out)\n",
        "# out = Lambda(lambda x: x**2+x)(out)\n",
        "out = AveragePooling2D()(out)\n",
        "# out = Lambda(lambda x: x*4)(out)\n",
        "out = Conv2D(8, 3, use_bias=False)(out)\n",
        "out = BatchNormalization()(out)\n",
        "out = ReLU()(out)\n",
        "# out = Lambda(lambda x: x**2+x)(out)\n",
        "out = AveragePooling2D()(out)\n",
        "# out = Lambda(lambda x: x*4)(out)\n",
        "out = Flatten()(out)\n",
        "out = Dense(10, activation=None)(out)\n",
        "out = Softmax()(out)\n",
        "model = Model(inputs, out)"
      ],
      "metadata": {
        "id": "5TUZqKqVEzcE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_aware_model = quantize_model(model)"
      ],
      "metadata": {
        "id": "QMu4SdQDE0bv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_aware_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNB8G40_E1nl",
        "outputId": "1b528140-5262-461a-a56f-84f34152cf0c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " quantize_layer (QuantizeLay  (None, 28, 28, 1)        3         \n",
            " er)                                                             \n",
            "                                                                 \n",
            " quant_conv2d (QuantizeWrapp  (None, 26, 26, 4)        45        \n",
            " erV2)                                                           \n",
            "                                                                 \n",
            " quant_batch_normalization (  (None, 26, 26, 4)        17        \n",
            " QuantizeWrapperV2)                                              \n",
            "                                                                 \n",
            " quant_re_lu (QuantizeWrappe  (None, 26, 26, 4)        3         \n",
            " rV2)                                                            \n",
            "                                                                 \n",
            " quant_average_pooling2d (Qu  (None, 13, 13, 4)        3         \n",
            " antizeWrapperV2)                                                \n",
            "                                                                 \n",
            " quant_conv2d_1 (QuantizeWra  (None, 11, 11, 8)        305       \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_1  (None, 11, 11, 8)        33        \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_re_lu_1 (QuantizeWrap  (None, 11, 11, 8)        3         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_average_pooling2d_1 (  (None, 5, 5, 8)          3         \n",
            " QuantizeWrapperV2)                                              \n",
            "                                                                 \n",
            " quant_flatten (QuantizeWrap  (None, 200)              1         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_dense (QuantizeWrappe  (None, 10)               2015      \n",
            " rV2)                                                            \n",
            "                                                                 \n",
            " quant_softmax (QuantizeWrap  (None, 10)               1         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,432\n",
            "Trainable params: 2,358\n",
            "Non-trainable params: 74\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_aware_model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=SGD(learning_rate=0.01, momentum=0.9),\n",
        "    metrics=['acc']\n",
        "    )"
      ],
      "metadata": {
        "id": "svS4mnhGE2dp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_aware_model.fit(X_train, y_train, epochs=15, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIEaD9vOE32A",
        "outputId": "a8c6e838-3faa-438b-dd22-4a932f91bb89"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 23s 11ms/step - loss: 0.2013 - acc: 0.9406 - val_loss: 0.1018 - val_acc: 0.9677\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0842 - acc: 0.9743 - val_loss: 0.0808 - val_acc: 0.9740\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0694 - acc: 0.9788 - val_loss: 0.0584 - val_acc: 0.9813\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0608 - acc: 0.9815 - val_loss: 0.0538 - val_acc: 0.9824\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0556 - acc: 0.9832 - val_loss: 0.0481 - val_acc: 0.9853\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0506 - acc: 0.9843 - val_loss: 0.0464 - val_acc: 0.9850\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0485 - acc: 0.9849 - val_loss: 0.0670 - val_acc: 0.9779\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0453 - acc: 0.9858 - val_loss: 0.0448 - val_acc: 0.9860\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0432 - acc: 0.9867 - val_loss: 0.0566 - val_acc: 0.9823\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0419 - acc: 0.9874 - val_loss: 0.0385 - val_acc: 0.9870\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0397 - acc: 0.9876 - val_loss: 0.0453 - val_acc: 0.9850\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0389 - acc: 0.9880 - val_loss: 0.0597 - val_acc: 0.9816\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0372 - acc: 0.9885 - val_loss: 0.0439 - val_acc: 0.9847\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0360 - acc: 0.9887 - val_loss: 0.0357 - val_acc: 0.9884\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0356 - acc: 0.9889 - val_loss: 0.0400 - val_acc: 0.9857\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8045540d10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "model = converter.convert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1-DT7H_E4xN",
        "outputId": "0c43a3df-9006-4f78-c8e4-4e98c68c7fbf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 16). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Create interpreter, allocate tensors\n",
        "'''\n",
        "tflite_interpreter = tf.lite.Interpreter(model_content=model)\n",
        "tflite_interpreter.allocate_tensors()\n",
        "\n",
        "'''\n",
        "Check input/output details\n",
        "'''\n",
        "input_details = tflite_interpreter.get_input_details()\n",
        "output_details = tflite_interpreter.get_output_details()\n",
        "\n",
        "print(\"== Input details ==\")\n",
        "print(\"name:\", input_details[0]['name'])\n",
        "print(\"shape:\", input_details[0]['shape'])\n",
        "print(\"type:\", input_details[0]['dtype'])\n",
        "print(\"\\n== Output details ==\")\n",
        "print(\"name:\", output_details[0]['name'])\n",
        "print(\"shape:\", output_details[0]['shape'])\n",
        "print(\"type:\", output_details[0]['dtype'])\n",
        "\n",
        "'''\n",
        "This gives a list of dictionaries. \n",
        "'''\n",
        "tensor_details = tflite_interpreter.get_tensor_details()\n",
        "\n",
        "for dict in tensor_details:\n",
        "    i = dict['index']\n",
        "    tensor_name = dict['name']\n",
        "    scales = dict['quantization_parameters']['scales']\n",
        "    zero_points = dict['quantization_parameters']['zero_points']\n",
        "    tensor = tflite_interpreter.tensor(i)()\n",
        "\n",
        "    print(i, type, tensor_name, scales.shape, zero_points.shape, tensor.shape)\n",
        "    # print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHt-zIshF0pv",
        "outputId": "64c1d7bc-2d24-42c5-d223-6ad12cfde19c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Input details ==\n",
            "name: serving_default_input_1:0\n",
            "shape: [ 1 28 28  1]\n",
            "type: <class 'numpy.float32'>\n",
            "\n",
            "== Output details ==\n",
            "name: StatefulPartitionedCall:0\n",
            "shape: [ 1 10]\n",
            "type: <class 'numpy.float32'>\n",
            "0 <class 'type'> serving_default_input_1:0 (0,) (0,) (1, 28, 28, 1)\n",
            "1 <class 'type'> model/quant_flatten/Const (0,) (0,) (2,)\n",
            "2 <class 'type'> model/quant_dense/BiasAdd/ReadVariableOp (1,) (1,) (10,)\n",
            "3 <class 'type'> model/quant_batch_normalization_1/FusedBatchNormV3 (8,) (8,) (8,)\n",
            "4 <class 'type'> model/quant_batch_normalization/FusedBatchNormV3 (4,) (4,) (4,)\n",
            "5 <class 'type'> model/quantize_layer/AllValuesQuantize/FakeQuantWithMinMaxVars;model/quantize_layer/AllValuesQuantize/FakeQuantWithMinMaxVars/ReadVariableOp;model/quantize_layer/AllValuesQuantize/FakeQuantWithMinMaxVars/ReadVariableOp_1 (1,) (1,) (1, 28, 28, 1)\n",
            "6 <class 'type'> model/quant_conv2d/Conv2D;model/quant_conv2d/LastValueQuant/FakeQuantWithMinMaxVarsPerChannel (4,) (4,) (4, 3, 3, 1)\n",
            "7 <class 'type'> model/quant_re_lu/Relu;model/quant_batch_normalization/FusedBatchNormV3;model/quant_conv2d/Conv2D (1,) (1,) (1, 26, 26, 4)\n",
            "8 <class 'type'> model/quant_average_pooling2d/AvgPool (1,) (1,) (1, 13, 13, 4)\n",
            "9 <class 'type'> model/quant_average_pooling2d/MovingAvgQuantize/FakeQuantWithMinMaxVars;model/quant_average_pooling2d_1/MovingAvgQuantize/FakeQuantWithMinMaxVars/ReadVariableOp;model/quant_average_pooling2d/MovingAvgQuantize/FakeQuantWithMinMaxVars/ReadVariableOp_1 (1,) (1,) (1, 13, 13, 4)\n",
            "10 <class 'type'> model/quant_conv2d_1/Conv2D;model/quant_conv2d_1/LastValueQuant/FakeQuantWithMinMaxVarsPerChannel (8,) (8,) (8, 3, 3, 4)\n",
            "11 <class 'type'> model/quant_re_lu_1/Relu;model/quant_batch_normalization_1/FusedBatchNormV3;model/quant_conv2d_1/Conv2D (1,) (1,) (1, 11, 11, 8)\n",
            "12 <class 'type'> model/quant_average_pooling2d_1/AvgPool (1,) (1,) (1, 5, 5, 8)\n",
            "13 <class 'type'> model/quant_average_pooling2d_1/AvgPool1 (1,) (1,) (1, 5, 5, 8)\n",
            "14 <class 'type'> model/quant_flatten/Reshape;model/quant_average_pooling2d_1/MovingAvgQuantize/FakeQuantWithMinMaxVars (1,) (1,) (1, 200)\n",
            "15 <class 'type'> model/quant_dense/MatMul;model/quant_dense/LastValueQuant/FakeQuantWithMinMaxVars (1,) (1,) (10, 200)\n",
            "16 <class 'type'> model/quant_dense/MatMul;model/quant_dense/BiasAdd (1,) (1,) (1, 10)\n",
            "17 <class 'type'> model/quant_softmax/Softmax (1,) (1,) (1, 10)\n",
            "18 <class 'type'> StatefulPartitionedCall:0 (0,) (0,) (1, 10)\n",
            "25 <class 'type'>  (0,) (0,) (1, 26, 26, 9)\n",
            "26 <class 'type'>  (0,) (0,) (1, 11, 11, 36)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PkoSWwvnIKsP"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}